{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c723b2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a883be0",
   "metadata": {},
   "source": [
    "### Setup Kaggle Credentials:\n",
    "\n",
    "1. Go to https://www.kaggle.com/\n",
    "2. Sign in or create an account\n",
    "3. Go to Account Settings (click your profile picture ‚Üí Account)\n",
    "4. Scroll to \"API\" section\n",
    "5. Click \"Create New API Token\"\n",
    "6. This downloads `kaggle.json` file\n",
    "7. Upload it to this notebook or your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a217866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "!unzip -q chest-xray-pneumonia.zip -d ./dataset\n",
    "print(\"‚úÖ Dataset downloaded and extracted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812853f",
   "metadata": {},
   "source": [
    "### Method 2: Manual Download\n",
    "\n",
    "If Kaggle API doesn't work:\n",
    "\n",
    "1. Visit: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
    "2. Click \"Download\" button\n",
    "3. Extract the zip file\n",
    "4. Upload to your notebook environment\n",
    "\n",
    "Dataset structure:\n",
    "```\n",
    "chest_xray/\n",
    "‚îú‚îÄ‚îÄ train/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/\n",
    "‚îú‚îÄ‚îÄ test/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ NORMAL/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ PNEUMONIA/\n",
    "‚îî‚îÄ‚îÄ val/\n",
    "    ‚îú‚îÄ‚îÄ NORMAL/\n",
    "    ‚îî‚îÄ‚îÄ PNEUMONIA/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5a177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas opencv-python scikit-image PyWavelets Pillow matplotlib seaborn scikit-learn xgboost ipywidgets\n",
    "print(\"‚úÖ All packages installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8328f24a",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ Step 2: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226d647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pywt\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Interactive widgets\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75c6b59",
   "metadata": {},
   "source": [
    "## üîß Step 4: Define Feature Extraction Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f670dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rotation_invariant_glcm_features(image_array, distance=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], levels=32):\n",
    "\n",
    "    image_array = image_array.astype(np.uint8)\n",
    "    max_val = image_array.max()\n",
    "    if max_val >= levels:\n",
    "        quantized_array = np.floor(image_array * ((levels - 1) / max_val)).astype(np.uint8)\n",
    "    else:\n",
    "        quantized_array = image_array\n",
    "\n",
    "    gcom = graycomatrix(\n",
    "        quantized_array,\n",
    "        distances=distance,\n",
    "        angles=angles,\n",
    "        levels=levels,\n",
    "        symmetric=True,\n",
    "        normed=True\n",
    "    )\n",
    "\n",
    "    dissimilarity = np.mean(graycoprops(gcom, 'dissimilarity'))\n",
    "    correlation = np.mean(graycoprops(gcom, 'correlation'))\n",
    "    homogeneity = np.mean(graycoprops(gcom, 'homogeneity'))\n",
    "    energy = np.mean(graycoprops(gcom, 'energy'))\n",
    "\n",
    "    return [dissimilarity, correlation, homogeneity, energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5315777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavelet_features(image_array, wavelet='haar', level=1):\n",
    "    coeffs = pywt.wavedec2(image_array.astype(float), wavelet, level=level)\n",
    "    LH, HL, HH = coeffs[1]\n",
    "\n",
    "    lh_energy = np.sum(LH**2)\n",
    "    hl_energy = np.sum(HL**2)\n",
    "    hh_energy = np.sum(HH**2)\n",
    "\n",
    "    return [lh_energy, hl_energy, hh_energy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_feature_embedding(image_path, resize_to=(128, 128), n_blocks=4, bit_depth=16):\n",
    "    if resize_to[0] % n_blocks != 0 or resize_to[1] % n_blocks != 0:\n",
    "        raise ValueError(\"resize_to dimensions must be divisible by n_blocks.\")\n",
    "\n",
    "    block_w = resize_to[0] // n_blocks\n",
    "    block_h = resize_to[1] // n_blocks\n",
    "\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('L')\n",
    "        img = img.resize(resize_to)\n",
    "        img_array = np.array(img).astype(np.uint8)\n",
    "\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        clahe_img = clahe.apply(img_array)\n",
    "\n",
    "        embedding = []\n",
    "        MAX_DISSIMILARITY = 16.0\n",
    "        MAX_INTENSITY = 255.0\n",
    "        MAX_WAVELET_ENERGY = 500000.0\n",
    "\n",
    "        for i in range(n_blocks):\n",
    "            for j in range(n_blocks):\n",
    "                block = clahe_img[i*block_h:(i+1)*block_h, j*block_w:(j+1)*block_w]\n",
    "\n",
    "                glcm_features = get_rotation_invariant_glcm_features(block)\n",
    "                wavelet_features = get_wavelet_features(block)\n",
    "                mean_intensity = np.mean(block)\n",
    "                std_intensity = np.std(block)\n",
    "\n",
    "                features = [\n",
    "                    min(glcm_features[0] / MAX_DISSIMILARITY, 1.0),\n",
    "                    (glcm_features[1] + 1.0) / 2.0,\n",
    "                    glcm_features[2],\n",
    "                    glcm_features[3],\n",
    "                    min(wavelet_features[0] / MAX_WAVELET_ENERGY, 1.0),\n",
    "                    min(wavelet_features[1] / MAX_WAVELET_ENERGY, 1.0),\n",
    "                    min(wavelet_features[2] / MAX_WAVELET_ENERGY, 1.0),\n",
    "                    mean_intensity / MAX_INTENSITY,\n",
    "                    std_intensity / MAX_INTENSITY\n",
    "                ]\n",
    "\n",
    "                for feat in features:\n",
    "                    scaled_value = int(feat * (2**bit_depth - 1))\n",
    "                    bin_str = bin(scaled_value)[2:].zfill(bit_depth)\n",
    "                    bin_list = [int(bit) for bit in bin_str]\n",
    "                    embedding.extend(bin_list)\n",
    "\n",
    "        return embedding\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc31314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_to_analog(embedding, bit_depth=16):\n",
    "    if not embedding:\n",
    "        return []\n",
    "    analog = []\n",
    "    for i in range(0, len(embedding), bit_depth):\n",
    "        bin_str = ''.join(str(bit) for bit in embedding[i:i+bit_depth])\n",
    "        value = int(bin_str, 2)\n",
    "        analog.append(value)\n",
    "    return analog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_em_wave(analog_values, feature_weights=None, carrier_freq=5,\n",
    "                     sampling_rate=50, duration_per_value=0.1, max_value=2**16 - 1):\n",
    "    if not analog_values:\n",
    "        return np.array([0]), np.array([0])\n",
    "\n",
    "    total_duration = len(analog_values) * duration_per_value\n",
    "    t = np.linspace(0, total_duration, int(total_duration * sampling_rate), endpoint=False)\n",
    "    wave = np.zeros_like(t)\n",
    "    samples_per_value = int(duration_per_value * sampling_rate)\n",
    "\n",
    "    if feature_weights is None:\n",
    "        feature_weights = np.ones(len(analog_values))\n",
    "\n",
    "    for i, value in enumerate(analog_values):\n",
    "        amp = value / max_value\n",
    "        weighted_amp = amp * feature_weights[i]\n",
    "\n",
    "        start = i * samples_per_value\n",
    "        end = min(start + samples_per_value, len(t))\n",
    "\n",
    "        if start < len(t):\n",
    "            wave[start:end] = weighted_amp * np.sin(2 * np.pi * carrier_freq * t[start:end])\n",
    "\n",
    "    return t, wave\n",
    "\n",
    "print(\"‚úÖ Feature extraction functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98377ba2",
   "metadata": {},
   "source": [
    "---\n",
    "## üìÇ Step 5: Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757e852",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './dataset/chest_xray/train'\n",
    "# Alternative paths you might need:\n",
    "# root_path = './chest_xray/train'  # If extracted differently\n",
    "# root_path = '/kaggle/input/chest-xray-pneumonia/chest_xray/train'  # For Kaggle notebooks\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "for label in os.listdir(root_path):\n",
    "    label_path = os.path.join(root_path, label)\n",
    "    if os.path.isdir(label_path):\n",
    "        for img_file in os.listdir(label_path):\n",
    "            if img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_paths.append(os.path.join(label_path, img_file))\n",
    "                labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(df)} images\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"\\nClasses: {df['label'].unique()}\")\n",
    "print(f\"\\nClass distribution:\\n{df['label'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19db27",
   "metadata": {},
   "source": [
    "## üìä Step 6: Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2075f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 5 samples:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "sns.countplot(data=df, x=\"label\", palette=\"viridis\", ax=ax1)\n",
    "ax1.set_title(\"Distribution of Classes\", fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel(\"Class\", fontsize=12)\n",
    "ax1.set_ylabel(\"Count\", fontsize=12)\n",
    "\n",
    "for p in ax1.patches:\n",
    "    ax1.annotate(f'{int(p.get_height())}',\n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=11, color='black',\n",
    "                xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "label_counts = df[\"label\"].value_counts()\n",
    "colors = sns.color_palette(\"viridis\", len(label_counts))\n",
    "ax2.pie(label_counts, labels=label_counts.index, autopct='%1.1f%%',\n",
    "       startangle=140, colors=colors, textprops={'fontsize': 10, 'weight': 'bold'},\n",
    "       wedgeprops={'edgecolor': 'black', 'linewidth': 1})\n",
    "ax2.set_title(\"Class Distribution - Pie Chart\", fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17428a7b",
   "metadata": {},
   "source": [
    "---\n",
    "## üñºÔ∏è Step 7: Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52758cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 5\n",
    "unique_labels = df['label'].unique()\n",
    "\n",
    "plt.figure(figsize=(15, len(unique_labels) * 3))\n",
    "\n",
    "for row_idx, label in enumerate(unique_labels):\n",
    "    label_images = df[df['label'] == label].head(num_images)['image_path'].tolist()\n",
    "    for col_idx, img_path in enumerate(label_images):\n",
    "        plt_idx = row_idx * num_images + col_idx + 1\n",
    "        plt.subplot(len(unique_labels), num_images, plt_idx)\n",
    "        img = Image.open(img_path)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        if col_idx == 2:\n",
    "            plt.title(label, fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6ed63",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öñÔ∏è Step 8: Balance Dataset (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af022504",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "max_samples = df['label'].value_counts().max()\n",
    "balanced_df = df.groupby('label', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=max_samples, replace=True, random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "df = balanced_df[['image_path', 'label']]\n",
    "\n",
    "print(\"\\n‚úÖ Balanced distribution:\")\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7656fa9",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Step 9: Extract Features from Images\n",
    "\n",
    "**‚ö†Ô∏è Warning:** This step is computationally intensive and may take several minutes depending on your dataset size.\n",
    "- Expect ~1-2 seconds per image\n",
    "- For 5,000 images, this could take 1-2 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00f460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SUBSET = False\n",
    "SUBSET_SIZE = 100 \n",
    "\n",
    "if USE_SUBSET:\n",
    "    df_sample = df.sample(n=SUBSET_SIZE, random_state=42).reset_index(drop=True)\n",
    "    print(f\"‚ö†Ô∏è Using subset of {SUBSET_SIZE} images for testing\")\n",
    "else:\n",
    "    df_sample = df.copy()\n",
    "    print(f\"Processing all {len(df_sample)} images\")\n",
    "\n",
    "print(\"\\nExtracting features... This may take a while ‚òï\")\n",
    "print(\"Progress:\")\n",
    "embeddings = []\n",
    "total = len(df_sample)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for idx, path in enumerate(df_sample['image_path']):\n",
    "    embedding = get_multi_feature_embedding(path)\n",
    "    embeddings.append(embedding)\n",
    "    if (idx + 1) % max(1, total // 10) == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        progress = (idx + 1) / total * 100\n",
    "        eta = (elapsed / (idx + 1)) * (total - idx - 1)\n",
    "        print(f\"  {progress:.1f}% ({idx+1}/{total}) - Elapsed: {elapsed:.1f}s - ETA: {eta:.1f}s\")\n",
    "\n",
    "df_sample['multi_feature_embedding'] = embeddings\n",
    "df_sample['multi_analog_values'] = df_sample['multi_feature_embedding'].apply(embedding_to_analog)\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Feature extraction complete! Total time: {total_time:.1f}s ({total_time/len(df_sample):.2f}s per image)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6205a812",
   "metadata": {},
   "source": [
    "---\n",
    "## üìà Step 10: Visualize EM Waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c7b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PLOTS = min(5, len(df_sample))\n",
    "fig, axes = plt.subplots(N_PLOTS, 1, figsize=(14, 2 * N_PLOTS))\n",
    "\n",
    "if N_PLOTS == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "plt.suptitle('Simulated EM Wave from Multi-Feature Embedding', fontsize=14, y=1.0)\n",
    "FEATURES_TO_PLOT = 50\n",
    "\n",
    "for i in range(N_PLOTS):\n",
    "    analog_values = df_sample['multi_analog_values'].iloc[i]\n",
    "    label = df_sample['label'].iloc[i]\n",
    "    analog_subsample = analog_values[:FEATURES_TO_PLOT]\n",
    "    t, wave = generate_em_wave(analog_subsample, carrier_freq=10, sampling_rate=100)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.plot(t, wave, color='purple', linewidth=1.5)\n",
    "    ax.set_title(f\"Image {i+1} - Label: {label}\", fontsize=10, loc='left')\n",
    "    ax.set_ylabel('Amplitude')\n",
    "    ax.set_ylim(-1.1, 1.1)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    if i < N_PLOTS - 1:\n",
    "        ax.set_xticks([])\n",
    "\n",
    "axes[-1].set_xlabel(f'Time (s) - Showing first {FEATURES_TO_PLOT} features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77943a9",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Step 11: Visualize Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fca203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_NAMES = [\n",
    "    'GLCM: Dissimilarity',\n",
    "    'GLCM: Correlation',\n",
    "    'GLCM: Homogeneity',\n",
    "    'GLCM: Energy',\n",
    "    'Wavelet: LH Energy',\n",
    "    'Wavelet: HL Energy',\n",
    "    'Wavelet: HH Energy',\n",
    "    'Intensity: Mean',\n",
    "    'Intensity: Std Dev'\n",
    "]\n",
    "N_FEATURES_PER_BLOCK = 9\n",
    "N_BLOCKS = 4\n",
    "\n",
    "analog_values = df_sample['multi_analog_values'].iloc[0]\n",
    "image_label = df_sample['label'].iloc[0]\n",
    "analog_matrix = np.array(analog_values).reshape(N_BLOCKS * N_BLOCKS, N_FEATURES_PER_BLOCK)\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 10))\n",
    "fig.suptitle(f'Feature Maps (Label: {image_label})', fontsize=16, y=0.98)\n",
    "\n",
    "for f_idx, feature_name in enumerate(FEATURE_NAMES):\n",
    "    feature_magnitudes = analog_matrix[:, f_idx]\n",
    "    feature_map = feature_magnitudes.reshape(N_BLOCKS, N_BLOCKS)\n",
    "    \n",
    "    ax = axes[f_idx // 3, f_idx % 3]\n",
    "    im = ax.imshow(feature_map, cmap='magma', interpolation='nearest')\n",
    "    ax.set_title(feature_name, fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.045, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1593e4",
   "metadata": {},
   "source": [
    "## ü§ñ Step 12: Prepare Data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf8e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_sample['multi_feature_embedding'].tolist())\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_sample['label'])\n",
    "target_names = le.classes_\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Classes: {target_names}\")\n",
    "print(f\"\\nClass encoding:\")\n",
    "for idx, name in enumerate(target_names):\n",
    "    print(f\"  {name}: {idx}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining set distribution:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {target_names[u]}: {c}\")\n",
    "print(f\"\\nTest set distribution:\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  {target_names[u]}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2a481",
   "metadata": {},
   "source": [
    "## üéì Step 13: Train Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, solver='liblinear', random_state=42),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "print(\"Training models...\\n\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    end_time = time.time()\n",
    "    train_time = end_time - start_time\n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'predictions': y_pred,\n",
    "        'report': classification_report(y_test, y_pred, target_names=target_names, output_dict=True),\n",
    "        'time': train_time\n",
    "    }\n",
    "    accuracy = results[name]['report']['accuracy']\n",
    "    print(f\"  ‚úì Trained in {train_time:.2f}s\")\n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(\"-\"*80)\n",
    "print(\"\\n‚úÖ All models trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a33ac7",
   "metadata": {},
   "source": [
    "## üìä Step 14: Model Comparison - Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f3388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "plt.suptitle('Model Comparison: Confusion Matrices', fontsize=16, y=0.995)\n",
    "\n",
    "for i, (name, res) in enumerate(results.items()):\n",
    "    if i >= len(axes):\n",
    "        break\n",
    "    \n",
    "    y_pred = res['predictions']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    acc = res['report']['accuracy']\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=target_names, yticklabels=target_names,\n",
    "                ax=axes[i], cbar_kws={'shrink': 0.8})\n",
    "    axes[i].set_title(f\"{name}\\nAccuracy: {acc:.4f}\", fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel('Predicted Label', fontsize=10)\n",
    "    axes[i].set_ylabel('True Label', fontsize=10)\n",
    "for i in range(len(results), len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ce639",
   "metadata": {},
   "source": [
    "## üìã Step 15: Detailed Performance Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e89695",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DETAILED CLASSIFICATION REPORTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, res in results.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"{name}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Training Time: {res['time']:.2f}s\\n\")\n",
    "    print(classification_report(y_test, res['predictions'], target_names=target_names))\n",
    "    print(f\"{'='*80}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb91d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for name, res in results.items():\n",
    "    report = res['report']\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': f\"{report['accuracy']:.4f}\",\n",
    "        'Precision (NORMAL)': f\"{report['NORMAL']['precision']:.4f}\",\n",
    "        'Recall (NORMAL)': f\"{report['NORMAL']['recall']:.4f}\",\n",
    "        'F1-Score (NORMAL)': f\"{report['NORMAL']['f1-score']:.4f}\",\n",
    "        'Precision (PNEUMONIA)': f\"{report['PNEUMONIA']['precision']:.4f}\",\n",
    "        'Recall (PNEUMONIA)': f\"{report['PNEUMONIA']['recall']:.4f}\",\n",
    "        'F1-Score (PNEUMONIA)': f\"{report['PNEUMONIA']['f1-score']:.4f}\",\n",
    "        'Training Time (s)': f\"{res['time']:.2f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY PERFORMANCE TABLE\")\n",
    "print(\"=\"*100)\n",
    "display(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c392710",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ Step 16: Predict Single Image (Interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image_path, model_name='Random Forest'):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    img = Image.open(image_path)\n",
    "    ax1.imshow(img, cmap='gray')\n",
    "    ax1.set_title('Input Chest X-Ray', fontsize=14, fontweight='bold')\n",
    "    ax1.axis('off')\n",
    "    print(\"Extracting features...\")\n",
    "    embedding = get_multi_feature_embedding(image_path)\n",
    "    \n",
    "    if embedding is None:\n",
    "        print(\"‚ùå Error: Could not process image\")\n",
    "        return\n",
    "    \n",
    "    X_input = np.array([embedding])\n",
    "    if model_name not in results:\n",
    "        print(f\"‚ùå Model '{model_name}' not found\")\n",
    "        return\n",
    "    \n",
    "    model = results[model_name]['model']\n",
    "    prediction = model.predict(X_input)[0]\n",
    "    label = le.inverse_transform([prediction])[0]\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        proba = model.predict_proba(X_input)[0]\n",
    "    else:\n",
    "        proba = None\n",
    "    result_text = f\"PREDICTION: {label}\\n\\n\"\n",
    "    result_text += f\"Model: {model_name}\\n\\n\"\n",
    "    \n",
    "    if proba is not None:\n",
    "        result_text += \"Confidence Scores:\\n\"\n",
    "        for idx, class_name in enumerate(target_names):\n",
    "            result_text += f\"  {class_name}: {proba[idx]*100:.2f}%\\n\"\n",
    "    \n",
    "    if label == \"PNEUMONIA\":\n",
    "        color = 'red'\n",
    "        result_text += \"\\n‚ö†Ô∏è WARNING: Pneumonia detected!\\n\"\n",
    "        result_text += \"Please consult a medical professional.\"\n",
    "    else:\n",
    "        color = 'green'\n",
    "        result_text += \"\\n‚úì Normal chest X-ray\"\n",
    "    \n",
    "    ax2.text(0.5, 0.5, result_text, ha='center', va='center', \n",
    "             fontsize=12, bbox=dict(boxstyle='round', facecolor=color, alpha=0.2),\n",
    "             transform=ax2.transAxes)\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.set_ylim(0, 1)\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title('Diagnosis Result', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return label, proba\n",
    "\n",
    "print(\"‚úÖ Prediction function ready!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b65bd8",
   "metadata": {},
   "source": [
    "test_image_idx = np.random.randint(0, len(df_sample))\n",
    "test_image_path = df_sample['image_path'].iloc[test_image_idx]\n",
    "true_label = df_sample['label'].iloc[test_image_idx]\n",
    "\n",
    "print(f\"Testing image {test_image_idx}\")\n",
    "print(f\"True label: {true_label}\\n\")\n",
    "\n",
    "predicted_label, confidence = predict_image(test_image_path, model_name='Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ca426",
   "metadata": {},
   "source": [
    "## üíæ Step 17: Save Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24788537",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data = {\n",
    "    'models': {name: res['model'] for name, res in results.items()},\n",
    "    'label_encoder': le,\n",
    "    'target_names': target_names\n",
    "}\n",
    "\n",
    "with open('pneumonia_models.pkl', 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "print(\"‚úÖ Models saved to 'pneumonia_models.pkl'\")\n",
    "print(f\"   File size: {os.path.getsize('pneumonia_models.pkl') / (1024*1024):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18506dcc",
   "metadata": {},
   "source": [
    "## üì• Step 18: Load Pre-trained Models (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ff299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(filepath='pneumonia_models.pkl'):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        save_data = pickle.load(f)\n",
    "    return save_data['models'], save_data['label_encoder'], save_data['target_names']\n",
    "\n",
    "# Uncomment to load:\n",
    "# loaded_models, le, target_names = load_models('pneumonia_models.pkl')\n",
    "# print(\"‚úÖ Models loaded successfully!\")\n",
    "# print(f\"   Available models: {list(loaded_models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f2de5",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Widget for Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5e2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dropdown = widgets.Dropdown(\n",
    "    options=list(results.keys()),\n",
    "    value='Random Forest',\n",
    "    description='Model:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "image_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=len(df_sample)-1,\n",
    "    step=1,\n",
    "    description='Image Index:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "predict_button = widgets.Button(\n",
    "    description='üîç Predict',\n",
    "    button_style='success',\n",
    "    tooltip='Click to predict',\n",
    "    icon='check'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "def on_predict_clicked(b):\n",
    "    with output:\n",
    "        clear_output(wait=True)\n",
    "        img_idx = image_slider.value\n",
    "        img_path = df_sample['image_path'].iloc[img_idx]\n",
    "        true_label = df_sample['label'].iloc[img_idx]\n",
    "        model_name = model_dropdown.value\n",
    "        \n",
    "        print(f\"Image Index: {img_idx}\")\n",
    "        print(f\"True Label: {true_label}\\n\")\n",
    "        \n",
    "        predict_image(img_path, model_name)\n",
    "\n",
    "predict_button.on_click(on_predict_clicked)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERACTIVE PREDICTION WIDGET\")\n",
    "print(\"=\"*80)\n",
    "display(widgets.VBox([model_dropdown, image_slider, predict_button, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb73f04",
   "metadata": {},
   "source": [
    "## üìä Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ PNEUMONIA DETECTION SYSTEM - COMPLETE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Information:\")\n",
    "print(f\"   Total images processed: {len(df_sample)}\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Test samples: {len(X_test)}\")\n",
    "print(f\"   Feature vector size: {X.shape[1]}\")\n",
    "\n",
    "print(f\"\\nü§ñ Models Trained: {len(results)}\")\n",
    "for name in results.keys():\n",
    "    print(f\"   ‚úì {name}\")\n",
    "\n",
    "print(f\"\\nüèÜ Best Model Performance:\")\n",
    "best_model = max(results.items(), key=lambda x: x[1]['report']['accuracy'])\n",
    "best_name = best_model[0]\n",
    "best_acc = best_model[1]['report']['accuracy']\n",
    "print(f\"   Model: {best_name}\")\n",
    "print(f\"   Accuracy: {best_acc:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Important Reminders:\")\n",
    "print(f\"   ‚Ä¢ This is for educational purposes only\")\n",
    "print(f\"   ‚Ä¢ Not approved for clinical diagnosis\")\n",
    "print(f\"   ‚Ä¢ Always consult medical professionals\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ System ready for predictions!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
